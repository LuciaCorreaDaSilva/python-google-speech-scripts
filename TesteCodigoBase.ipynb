{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TesteCodigoBase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuciaCorreaDaSilva/python-google-speech-scripts/blob/master/TesteCodigoBase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmvE08SgBRWa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "d831e1b0-545c-442a-f285-e9e9e4373cff"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import sys, io, os, shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#from pyaudioclassification.limpar import limpar\n",
        "\n",
        "from pyaudioclassification import *\n",
        "\n",
        "    \n",
        "dirName_data = list()\n",
        "dirName_results = list()\n",
        "my_dirs = [x[0] for x in os.walk(\"//data//usar no modelo\")]\n",
        "for i in my_dirs:\n",
        "    if (os.path.basename(os.path.normpath(i)) == \"dripping\"):\n",
        "        dirName_data.append(os.path.split(i)[0])\n",
        "        dirName_results.append(os.path.split(i)[0].replace(\"data\", \"resultados\"))\n",
        "\n",
        "posssiveis_redes = [\"cnn2d\", \"cnn\", \"lstm\", \"nn\"]\n",
        "\n",
        "n = len(dirName_data)\n",
        "local_dados = ''\n",
        "parent_dir = ''\n",
        "\n",
        "for i in range(0, n):\n",
        "    local_dados = dirName_data[i]\n",
        "    for type in posssiveis_redes:\n",
        "        parent_dir = dirName_results[i] + '//' + type\n",
        "        os.chdir(parent_dir)\n",
        "        \n",
        "        # if (type != \"cnn2d\"):\n",
        "        #     file = os.listdir(dirName_results[i] + '//' + \"cnn2d\")\n",
        "        #     for f in file:\n",
        "        #         if (os.path.splitext(f)[1] == \".png\"):\n",
        "        #             continue\n",
        "        #         else:\n",
        "        #             shutil.copy(dirName_results[i] + '//' + \"cnn2d\" + \"//\" + f, parent_dir)   \n",
        "        #     limpar(limpar=False, feat_label=False, model_history=True, samples=True)\n",
        "\n",
        "        # type = \"cnn2d\"\n",
        "        # local_dados = \"D://PythonVSCode//sintetico//data//usar no modelo//sinais concatenado SNR//com operacao estacionaria//SNR menos 12 db dripping menos 24 db nock\"\n",
        "        # parent_dir = \"D://PythonVSCode//sintetico//resultados//usar no modelo//sinais concatenado SNR//com operacao estacionaria//SNR menos 12 db dripping menos 24 db nock//cnn2d\"\n",
        "        # os.chdir(parent_dir)\n",
        "\n",
        "        random_state = 42\n",
        "        rand = 0\n",
        "        epochs = 100\n",
        "        amostras_separar = 'train_test_val'\n",
        "\n",
        "        # step 0: clean directory\n",
        "        #limpar(limpar=False, feat_label=False, model_history=False, samples=False)\n",
        "            \n",
        "        # step 1: preprocessing\n",
        "        if np.DataSource().exists(\"./feat.npy\") and np.DataSource().exists(\"./label.npy\"):\n",
        "            features, labels = np.load('./feat.npy'), np.load('./label.npy')\n",
        "        else:\n",
        "            features, labels = feature_extraction(local_dados)\n",
        "            np.save('./feat.npy', features)\n",
        "            np.save('./label.npy', labels)\n",
        "            \n",
        "        if type == posssiveis_redes[0]:\n",
        "            for j in range(1,4):\n",
        "                test = dirName_results[i] + '//' + posssiveis_redes[j]\n",
        "                np.save(test + '//feat.npy', features)\n",
        "                np.save(test + '//label.npy', labels)\n",
        "\n",
        "        # If you don't specify the random_state in your code, then every time you run(execute) your code a new random value is generated and the train and test datasets would have different values each time.\n",
        "        # However, if a fixed value is assigned like random_state = 42 then no matter how many times you execute your code the result would be the same .i.e, same values in train and test datasets.\n",
        "        # https://stackoverflow.com/questions/28064634/random-state-pseudo-random-number-in-scikit-learn\n",
        "\n",
        "        # step 2: training       \n",
        "        if np.DataSource().exists(\"./model.h5\"):\n",
        "            from keras.models import load_model\n",
        "            model = load_model('./model.h5')\n",
        "            history = np.load('./history.npy', allow_pickle=True).item()\n",
        "        else:\n",
        "            model, history = train(features, labels, type, random_state=random_state, epochs=epochs)\n",
        "            model.save('./model.h5')\n",
        "            np.save('./history.npy', history.history)\n",
        "\n",
        "        # step 3: prediction, accuracy and loss\n",
        "        X_train = np.load(\"X_train.npy\")\n",
        "        y_train = np.load(\"y_train.npy\")\n",
        "        X_test = np.load(\"X_test.npy\")\n",
        "        y_test = np.load(\"y_test.npy\")\n",
        "\n",
        "        filename = 'Predict and accuracy - ' + type + ' ' + amostras_separar\n",
        "        sys.stdout = open(filename+\".txt\", \"w\")\n",
        "        print(filename)\n",
        "        print('')\n",
        "        \n",
        "\n",
        "        pred = predict(model, './X_test.npy', type=type)\n",
        "\n",
        "        _, _, train_acc, test_acc = acc_loss_fig(\n",
        "            X_train, y_train, model, history, type, amostras_separar, epochs,\n",
        "            X_test=X_test, y_test=y_test, save_fig=True, close_fig=True)\n",
        "\n",
        "        print('')\n",
        "        print_leaderboard(pred, local_dados, rand)\n",
        "        sys.stdout.close()\n",
        "\n",
        "\n",
        "        # step 4: Confusion matrix\n",
        "        labels = list(filter(lambda x: os.path.isdir(\n",
        "            os.path.join(local_dados, x)), os.listdir(local_dados)))\n",
        "        cm_analysis(y_test, pred, labels, type, amostras_separar, figsize=(10, 10),\n",
        "                    save_fig=True, close_fig=True)\n",
        "\n",
        "        # step 5: Classification report\n",
        "        plot_classification_report(y_test, pred, labels, type, amostras_separar, porcentagem=True,\n",
        "                                figsize=(10, 10), ax=None, save_fig=True, close_fig=True)\n",
        "\n",
        "        # # step 6: obtain summary\n",
        "        # summary_string = obter_model_summary(model, type, amostras_separar)\n",
        "\n",
        "\n",
        "        # step 4: Confusion matrix\n",
        "        labels = list(filter(lambda x: os.path.isdir(\n",
        "            os.path.join(local_dados, x)), os.listdir(local_dados)))\n",
        "        cm_analysis(y_test, pred, labels, type, amostras_separar, figsize=(10, 10),\n",
        "                    save_fig=True, close_fig=True)\n",
        "\n",
        "        # step 5: Classification report\n",
        "        plot_classification_report(y_test, pred, labels, type, amostras_separar, porcentagem=False,\n",
        "                                figsize=(10, 10), ax=None, save_fig=True, close_fig=True)\n",
        "\n",
        "        # # step 6: obtain summary\n",
        "        # summary_string = obter_model_summary(model, type, amostras_separar)\n",
        "        \n",
        "        # from numba import cuda \n",
        "        # device = cuda.get_current_device()\n",
        "        # device.reset()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-be8f01756890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#from pyaudioclassification.limpar import limpar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyaudioclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyaudioclassification'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StYDzQ6KBNCE"
      },
      "source": [
        "# Nova seção"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMUeZ7gL-BHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f06624a-b319-4e5b-ad0b-9cd78473322a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfxY8eb49Z9e"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}